{
 "cells": [
  {
   "source": [
    "# Proyecto ACutStic\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Programar una herramienta para Adobe Premiere que permita automatizar el proceso de edición de audio. La herramienta deberá seleccionar y cortar trozos de audio similares automáticamente.\n",
    "\n",
    "## Dot CSV\n",
    "\n",
    "Proyecto realizado en el contexto #100HorasDeML de dotCSV y resubido en el canal secundario Not CSV.\n",
    "\n",
    "- [Twich](https://www.twitch.tv/dotcsv)\n",
    "- [Youtube - Canal principal](https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg)\n",
    "- [Youtube - Canal secundario](https://www.youtube.com/c/NotCSV)\n",
    "- [Twitter](https://twitter.com/DotCSV)\n",
    "\n",
    "## Dependencias\n",
    "\n",
    "Para este proyecto se utilizará:\n",
    "\n",
    "- [Pymiere](https://github.com/qmasingarbe/pymiere)\n",
    "- [Librosa](https://librosa.org/doc/latest/index.html)\n",
    "- [Moviepy](https://pypi.org/project/moviepy/)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## Inicialización Pymiere\n",
    "\n",
    "- Obtención de la secuencia activa\n",
    "- Listado de videos de la secuencia\n",
    "- Obtención de datos de la secuencia (Ej. FPS)\n",
    "- Apertura de un video desde el FileSystem hacia Premiere\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pymiere\n",
    "\n",
    "from pymiere import wrappers\n",
    "\n",
    "# Checkear si existe un proyecto abierto\n",
    "project_opened, sequence_active = wrappers.check_active_sequence(crash=False)\n",
    "if not project_opened:\n",
    "    raise ValueError(\"please open a project\")\n",
    "\n",
    "project = pymiere.objects.app.project\n",
    "\n",
    "# Abrir secuencias en la Interface si no hay ninguna activa\n",
    "if not sequence_active:\n",
    "    sequences = wrappers.list_sequences()\n",
    "    for seq in sequences:\n",
    "        project.openSequence(sequenceID=seq.sequenceID)\n",
    "    project.activeSequence = sequences[0]  # set the first sequence in the list as active\n",
    "\n",
    "# Listar todos los videos en la secuencia activa\n",
    "clips = wrappers.list_video(project.activeSequence)\n",
    "\n",
    "# Obtener los FPS de la secuencia get sequence fps\n",
    "fps = 1/(float(project.activeSequence.timebase)/wrappers.TICKS_PER_SECONDS)\n",
    "\n",
    "print(\"Sequence as a framerate of {} fps\".format(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFile = r'C:\\Users\\Carlos\\Twitch\\Laboratorio\\01.Proyecto ACutStic\\input-navidad.mp4'\n",
    "\n",
    "# Abrimos en el proyecto el archivo de video deseado.\n",
    "pymiere.objects.app.sourceMonitor.openFilePath(pathFile)"
   ]
  },
  {
   "source": [
    "## Extracción del track de audio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "\n",
    "videoclip = VideoFileClip(pathFile) \n",
    "audioclip = videoclip.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioclip.write_audiofile('./output/audiofile.wav')"
   ]
  },
  {
   "source": [
    "---\n",
    "## Librosa\n",
    "\n",
    "- Obtención de la onda de audio.\n",
    "- Obtención del Sample Rate del audio.\n",
    "- Conversión de unidad Amplitud -> dB\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_waveform_amplitude, sample_rate = lb.load(pathFile, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_waveform = lb.amplitude_to_db(audio_waveform_amplitude)"
   ]
  },
  {
   "source": [
    "## Selección de puntos de corte\n",
    "\n",
    "- Establecimiento del tamaño de ventana de procesamiento\n",
    "- Establecimiendo de un umbral\n",
    "- Establecimiendo de un cooldown\n",
    "- Elección de puntos de corte"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size     = int(sample_rate / 2)\n",
    "threshold       = 60\n",
    "cooldown        = 5\n",
    "cooldown_count  = cooldown\n",
    "cut_points      = np.array([0]) # Añadido inpoint inicial.\n",
    "is_lower        = False \n",
    "\n",
    "for i in np.arange(0, sy.shape[0], window_size):\n",
    "    \n",
    "    # Seleccionamos los datos dentro de la ventana.\n",
    "    audio_window = audio_waveform[i:(window_size + i)]\n",
    "\n",
    "\n",
    "    # Si estamos por debajo del umbral, y veníamos de arriba...\n",
    "    win_est = np.abs(np.mean(audio_window))\n",
    "        \n",
    "    if win_est <= threshold:\n",
    "        \n",
    "        if not is_lower: \n",
    "            # Guardamos el sample rate.\n",
    "            cut_points = np.append(cut_points, i)\n",
    "            is_lower = True\n",
    "            cooldown_count = cooldown\n",
    "            \n",
    "    elif is_lower and cooldown_count <= 0:\n",
    "        is_lower = False\n",
    "        cut_points = np.append(cut_points, i)\n",
    "        cooldown_count = cooldown\n",
    "        \n",
    "    cooldown_count -= 1\n",
    "\n",
    "print('Puntos de corte: {}'.format(len(cut_points)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sr"
   ]
  },
  {
   "source": [
    "## Visualización de puntos de corte"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from librosa.display import waveplot\n",
    "\n",
    "plt.figure(figsize=(20, 10))    \n",
    "lb.display.waveplot(audio_waveform_amplitude, sample_rate)\n",
    "plt.scatter(cut_points / sample_rate, np.zeros(len(cut_points)), c=\"red\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))    \n",
    "# plt.scatter(cut_points, np.zeros(len(cut_points)), c=\"red\")\n",
    "plt.plot(audio_waveform)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "## Inserción de clips cortados\n",
    "\n",
    "- Extracción de puntos de corte\n",
    "- Inserción en tracks separados\n",
    "- Etiquetado/Coloreado de clips\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymiere.core import PymiereBaseObject, PymiereBaseCollection, Array, _format_object_to_py, _format_object_to_es\n",
    "\n",
    "project_vid = project.rootItem.children[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setColorLabel(clip, label): \n",
    "    clip._eval_on_this_object(\"setColorLabel({})\".format(_format_object_to_es(label)))\n",
    "\n",
    "def getColorLabel(position):\n",
    "    return 8 + abs(1 - position % 2) * 2\n",
    "\n",
    "def getTrack(position):\n",
    "    return (position % 2) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = 0\n",
    "clip = project.rootItem.children[-1]\n",
    "\n",
    "to_remove = True\n",
    "\n",
    "for i in range(len(cut_points) - 1):\n",
    "    \n",
    "        in_point = cut_points[i]    / sample_rate\n",
    "        out_point = cut_points[i+1] / sample_rate\n",
    "\n",
    "        print('InPoint: {} - OutPoint: {}'.format(in_point, out_point))\n",
    "\n",
    "        clip.setInPoint(in_point,  4)\n",
    "        clip.setOutPoint(out_point, 4)\n",
    "        \n",
    "        setColorLabel(clip, getColorLabel(i))\n",
    "        project.activeSequence.videoTracks[getTrack(i)].insertClip(clip, timestamp)\n",
    "\n",
    "        timestamp += (out_point - in_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}